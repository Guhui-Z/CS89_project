{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "spread-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "import json\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-shield",
   "metadata": {},
   "source": [
    "# Get Covid data from api.covidtracking.com\n",
    "1. suppose 'data' is the retrieved json, then it has keys ['links', 'meta', 'data']<br>\n",
    "2. For us/daily, data['data'] stores daily number of cases, with keys ['date', 'states', 'cases', 'testing', 'outcomes']<br>\n",
    "['date'] is the date in YYYY-MM-DD<br>\n",
    "['state'] is the number of states<br>\n",
    "['cases'] has a single key ['total'] with ['value'] (raw number) and ['calculated'] (some statistics)<br>\n",
    "['testing'] is structured the same way as ['cases']<br>\n",
    "['outcomes']<br>\n",
    "3. For state/daily, data['data'] has keys ['date', 'state', 'meta', 'cases', 'tests', 'outcomes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "shared-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_codes():\n",
    "    l = 'https://api.covidtracking.com/v2/states.json'\n",
    "    with urllib.request.urlopen(l) as url:\n",
    "        link_json = json.load(url)\n",
    "    pd.DataFrame(link_json['data']).to_csv('./data/states.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "final-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_json(link):\n",
    "    try:\n",
    "        with urllib.request.urlopen(link) as url:\n",
    "            link_json = json.load(url)\n",
    "        filename = './data/' + link.split('v2/')[1].replace('/', '_')\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(link_json, f)\n",
    "        print('saved ' + filename)\n",
    "        if filename != './data/us_daily.json':\n",
    "            covid_files.append(filename)\n",
    "    except:\n",
    "        print('retrieval failed ' + link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eleven-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_json():\n",
    "    global state_codes\n",
    "    covidtracking_api = 'https://api.covidtracking.com/v2/'\n",
    "    \n",
    "    retrieve_json(covidtracking_api+'us/daily.json')\n",
    "    \n",
    "    states_codes = pd.read_csv('./data/states.csv')['state_code'].str.lower()\n",
    "    for state in states_codes:\n",
    "        retrieve_json(covidtracking_api + 'states/' + state + '/daily/simple.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "settled-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_from_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        temp = json.load(f)\n",
    "    temp = pd.DataFrame(temp['data'])\n",
    "    \n",
    "    if filename != './data/us_daily.json':\n",
    "        temp['cases_total'] = temp['cases'].apply(lambda x: x['total'])\n",
    "        temp['cases_confirmed'] = temp['cases'].apply(lambda x: x['confirmed'])\n",
    "        temp['cases_probable'] = temp['cases'].apply(lambda x: x['probable'])\n",
    "        temp['tests_total'] = temp['tests'].apply(lambda x: x['pcr']['specimens']['total'])\n",
    "        temp['tests_positive'] = temp['tests'].apply(lambda x: x['pcr']['specimens']['positive'])\n",
    "        temp = temp.drop(['cases', 'tests'], axis=1)\n",
    "        temp.to_csv(filename.replace('json', 'csv'))\n",
    "        print('saved ' + filename.replace('json', 'csv'))\n",
    "    else:\n",
    "        temp['cases_total'] = temp['cases'].apply(lambda x: x['total']['value'])\n",
    "        temp['cases_percent'] = temp['cases'].apply(lambda x: x['total']['calculated']['population_percent'])\n",
    "        temp['cases_increase'] = temp['cases'].apply(lambda x: x['total']['calculated']['change_from_prior_day'])\n",
    "        temp['cases_7d_change'] = temp['cases'].apply(lambda x: x['total']['calculated']['seven_day_change_percent'])\n",
    "        temp['testing_total'] = temp['testing'].apply(lambda x: x['total']['value'])\n",
    "        temp['testing_percent'] = temp['testing'].apply(lambda x: x['total']['calculated']['population_percent'])\n",
    "        temp['testing_increase'] = temp['testing'].apply(lambda x: x['total']['calculated']['change_from_prior_day'])\n",
    "        temp['testing_7d_change'] = temp['testing'].apply(lambda x: x['total']['calculated']['seven_day_change_percent'])\n",
    "        temp = temp.drop(['cases', 'testing'], axis=1)\n",
    "        temp.to_csv('./data/us_daily.csv')\n",
    "        print('saved us_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "otherwise-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all_df():\n",
    "    clean_df_from_json('./data/us_daily.json')\n",
    "    for file in covid_files:\n",
    "        clean_df_from_json(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "pacific-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_state_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "killing-helen",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved states_al_daily_simple.json\n",
      "saved states_ak_daily_simple.json\n",
      "saved states_az_daily_simple.json\n",
      "saved states_ar_daily_simple.json\n",
      "saved states_ca_daily_simple.json\n",
      "saved states_co_daily_simple.json\n",
      "saved states_ct_daily_simple.json\n",
      "saved states_de_daily_simple.json\n",
      "saved states_dc_daily_simple.json\n",
      "saved states_fl_daily_simple.json\n",
      "saved states_ga_daily_simple.json\n",
      "saved states_hi_daily_simple.json\n",
      "saved states_id_daily_simple.json\n",
      "saved states_il_daily_simple.json\n",
      "saved states_in_daily_simple.json\n",
      "saved states_ia_daily_simple.json\n",
      "saved states_ks_daily_simple.json\n",
      "saved states_ky_daily_simple.json\n",
      "saved states_la_daily_simple.json\n",
      "saved states_me_daily_simple.json\n",
      "saved states_md_daily_simple.json\n",
      "saved states_ma_daily_simple.json\n",
      "saved states_mi_daily_simple.json\n",
      "saved states_mn_daily_simple.json\n",
      "saved states_ms_daily_simple.json\n",
      "saved states_mo_daily_simple.json\n",
      "saved states_mt_daily_simple.json\n",
      "saved states_ne_daily_simple.json\n",
      "saved states_nv_daily_simple.json\n",
      "saved states_nh_daily_simple.json\n",
      "saved states_nj_daily_simple.json\n",
      "saved states_nm_daily_simple.json\n",
      "saved states_ny_daily_simple.json\n",
      "saved states_nc_daily_simple.json\n",
      "saved states_nd_daily_simple.json\n",
      "saved states_oh_daily_simple.json\n",
      "saved states_ok_daily_simple.json\n",
      "saved states_or_daily_simple.json\n",
      "saved states_pa_daily_simple.json\n",
      "saved states_pr_daily_simple.json\n",
      "saved states_ri_daily_simple.json\n",
      "saved states_sc_daily_simple.json\n",
      "saved states_sd_daily_simple.json\n",
      "saved states_tn_daily_simple.json\n",
      "saved states_tx_daily_simple.json\n",
      "saved states_ut_daily_simple.json\n",
      "saved states_vt_daily_simple.json\n",
      "saved states_va_daily_simple.json\n",
      "saved states_vi_daily_simple.json\n",
      "saved states_wa_daily_simple.json\n",
      "saved states_wv_daily_simple.json\n",
      "saved states_wi_daily_simple.json\n",
      "saved states_wy_daily_simple.json\n"
     ]
    }
   ],
   "source": [
    "covid_files = []\n",
    "get_all_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "stable-local",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved us_daily.csv\n",
      "saved states_al_daily_simple.csv\n",
      "saved states_ak_daily_simple.csv\n",
      "saved states_az_daily_simple.csv\n",
      "saved states_ar_daily_simple.csv\n",
      "saved states_ca_daily_simple.csv\n",
      "saved states_co_daily_simple.csv\n",
      "saved states_ct_daily_simple.csv\n",
      "saved states_de_daily_simple.csv\n",
      "saved states_dc_daily_simple.csv\n",
      "saved states_fl_daily_simple.csv\n",
      "saved states_ga_daily_simple.csv\n",
      "saved states_hi_daily_simple.csv\n",
      "saved states_id_daily_simple.csv\n",
      "saved states_il_daily_simple.csv\n",
      "saved states_in_daily_simple.csv\n",
      "saved states_ia_daily_simple.csv\n",
      "saved states_ks_daily_simple.csv\n",
      "saved states_ky_daily_simple.csv\n",
      "saved states_la_daily_simple.csv\n",
      "saved states_me_daily_simple.csv\n",
      "saved states_md_daily_simple.csv\n",
      "saved states_ma_daily_simple.csv\n",
      "saved states_mi_daily_simple.csv\n",
      "saved states_mn_daily_simple.csv\n",
      "saved states_ms_daily_simple.csv\n",
      "saved states_mo_daily_simple.csv\n",
      "saved states_mt_daily_simple.csv\n",
      "saved states_ne_daily_simple.csv\n",
      "saved states_nv_daily_simple.csv\n",
      "saved states_nh_daily_simple.csv\n",
      "saved states_nj_daily_simple.csv\n",
      "saved states_nm_daily_simple.csv\n",
      "saved states_ny_daily_simple.csv\n",
      "saved states_nc_daily_simple.csv\n",
      "saved states_nd_daily_simple.csv\n",
      "saved states_oh_daily_simple.csv\n",
      "saved states_ok_daily_simple.csv\n",
      "saved states_or_daily_simple.csv\n",
      "saved states_pa_daily_simple.csv\n",
      "saved states_pr_daily_simple.csv\n",
      "saved states_ri_daily_simple.csv\n",
      "saved states_sc_daily_simple.csv\n",
      "saved states_sd_daily_simple.csv\n",
      "saved states_tn_daily_simple.csv\n",
      "saved states_tx_daily_simple.csv\n",
      "saved states_ut_daily_simple.csv\n",
      "saved states_vt_daily_simple.csv\n",
      "saved states_va_daily_simple.csv\n",
      "saved states_vi_daily_simple.csv\n",
      "saved states_wa_daily_simple.csv\n",
      "saved states_wv_daily_simple.csv\n",
      "saved states_wi_daily_simple.csv\n",
      "saved states_wy_daily_simple.csv\n",
      "saved states_as_daily_simple.csv\n",
      "saved states_gu_daily_simple.csv\n",
      "saved states_mp_daily_simple.csv\n"
     ]
    }
   ],
   "source": [
    "clean_all_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-bennett",
   "metadata": {},
   "source": [
    "# Get Covid data (of March 10) from worldometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "universal-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdm = 'https://www.worldometers.info/coronavirus/country/us/'\n",
    "wdm_page = requests.get(wdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "express-index",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " 'USAState',\n",
       " 'TotalCases',\n",
       " 'NewCases',\n",
       " 'TotalDeaths',\n",
       " 'NewDeaths',\n",
       " 'TotalRecovered',\n",
       " 'ActiveCases',\n",
       " 'Tot\\xa0Cases/1M pop',\n",
       " 'Deaths/1M pop',\n",
       " 'TotalTests',\n",
       " 'Tests/ 1M pop',\n",
       " 'Population',\n",
       " 'Projections']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_html(wdm_page.content)[1]\n",
    "df.columns.to_list() # check weird column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "blind-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change weird column names\n",
    "df = df.rename(columns={'Tot\\xa0Cases/1M pop': 'TotCasesPer1MPop', \n",
    "                        'Deaths/1M pop':'DeathsPer1MPop', 'Tests/ 1M pop': 'TestsPer1MPop'})\n",
    "df.to_csv('./data/us_0310.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-reward",
   "metadata": {},
   "source": [
    "# Get weather data from api.weather.gov (abandoned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-alfred",
   "metadata": {},
   "source": [
    "1. county -> severals zones -> several stations\n",
    "2. county observations are completely empty\n",
    "3. county observationStations are also empty<br>\n",
    "Abandoned because the api does not provide enough data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "union-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the county_stations is always empty as returned by the api, so we have another function\n",
    "# get_state_stations\n",
    "def get_state_counties(state):\n",
    "    state_abbr = states[states['name']==state]['state_code'].values[0]\n",
    "    t = f'https://api.weather.gov/zones?area={state_abbr}&type=county'\n",
    "    with urllib.request.urlopen(t) as url:\n",
    "            k = url.read()\n",
    "    print(t + ' api call is successful')\n",
    "    j = json.loads(k)['features']\n",
    "    \n",
    "    county_links = [item['id'] for item in j]\n",
    "    county_ids = [item['properties']['id'] for item in j]\n",
    "    county_names = [item['properties']['name'] for item in j]\n",
    "    county_states = [item['properties']['state'] for item in j]\n",
    "    county_stations = [item['properties']['observationStations'] for item in j] # empty\n",
    "    \n",
    "    df = pd.DataFrame({'link': county_links, 'id': county_ids, 'name': county_names,\n",
    "                      'state_code': county_states, 'stations': county_stations})\n",
    "    df['state'] = [state]*len(j)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ranking-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the api does not show any stations for a given county, so we have to get all stations in\n",
    "# a state and match them to their counties\n",
    "def get_state_stations(state):\n",
    "    state_abbr = states[states['name']==state]['state_code'].values[0]\n",
    "    t = f'https://api.weather.gov/stations?state={state_abbr}'\n",
    "    with urllib.request.urlopen(t) as url:\n",
    "            k = url.read()\n",
    "    print(t + ' api call is successful')\n",
    "    j = json.loads(k)['features']\n",
    "    \n",
    "    station_forecasts = []\n",
    "    for i, item in enumerate(j):\n",
    "        if 'forecast' in item['properties'].keys():\n",
    "            station_forecasts.append(item['properties']['forecast'])\n",
    "        else:\n",
    "            station_forecasts.append(np.nan)\n",
    "\n",
    "    station_counties = []\n",
    "    for i, item in enumerate(j):\n",
    "        if 'county' in item['properties'].keys():\n",
    "            station_counties.append(item['properties']['county'].split('/')[-1])\n",
    "        else:\n",
    "            station_counties.append(np.nan)\n",
    "    \n",
    "    df = pd.DataFrame({'forecast': station_forecasts, 'county': station_counties})\n",
    "    df = df.dropna(axis=0)\n",
    "    df = df.drop_duplicates(ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "engaging-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_county_pair(state):\n",
    "    counties_of_state = get_state_counties(state)\n",
    "    stations_of_state = get_state_stations(state)\n",
    "    df = pd.merge(cali, cali_station, left_on='id', right_on='county', \n",
    "                  suffixes=['_county', '_station'])\n",
    "    df = df.drop('county', axis=1)\n",
    "    df.to_csv(f'./data/{state}_station_county_pair.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_weather(state):\n",
    "    station_county_map = pd.read_csv(f'./data/{state}_station_county_pair.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "wireless-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.read_csv('./data/states.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "directed-payday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.weather.gov/zones?area=CA&type=county api call is successful\n",
      "https://api.weather.gov/stations?state=CA api call is successful\n"
     ]
    }
   ],
   "source": [
    "get_station_county_pair('California')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-twelve",
   "metadata": {},
   "source": [
    "# Get weather data from NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "working-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatypes = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/datatypes?limit=1000'\n",
    "datatypes_r = requests.get(datatypes, headers={'token': token})\n",
    "\n",
    "temp = json.loads(datatypes_r.text)['results']\n",
    "mindate = [item['mindate'] for item in temp]\n",
    "maxdate = [item['maxdate'] for item in temp]\n",
    "name = [item['name'] for item in temp]\n",
    "_id = [item['id'] for item in temp]\n",
    "df = pd.DataFrame({'mindate': mindate, 'maxdate': maxdate, 'name': name, 'id': _id})\n",
    "df.to_csv('noaa_datatypes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "homeless-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_county_weather(state):\n",
    "    county_fips = us_counties[us_counties['state']==state]['fips'].unique()\n",
    "    params = '&startdate=2020-01-01&enddate=2021-03-08&datatypeid=TAVG&limit=1000'\n",
    "    total = pd.DataFrame()\n",
    "    print(f'{len(county_fips)} counties')\n",
    "    for fips in county_fips:\n",
    "        link = noaa_api + f'&locationid=FIPS:{int(fips)}' + params\n",
    "        r = requests.get(l, headers={'token': token})\n",
    "        if r.status_code != 200:\n",
    "            print(fips, 'failed')\n",
    "            continue\n",
    "        print(fips, 'connected', end=' ')\n",
    "        d = json.loads(r.text)['results']\n",
    "        dates = [item['date'] for item in d]\n",
    "        values = [item['value'] for item in d]\n",
    "        df = pd.DataFrame({'TAVG': values, 'date': dates})\n",
    "        df['fips'] = [fips] * len(d)\n",
    "\n",
    "        mean_tavg = df.groupby(['fips', 'date'])['TAVG'].mean().values\n",
    "        df = df.drop('TAVG', axis=1)\n",
    "        df = df.drop_duplicates(ignore_index=True)\n",
    "        df['mean_temp'] = mean_tavg\n",
    "\n",
    "        total = pd.concat((total, df))\n",
    "    total.to_csv(f'./weather_data/{state}_weather.csv')\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "fluid-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_counties = pd.read_csv('./data/us-counties.csv')\n",
    "us_counties['date'] = pd.to_datetime(us_counties['date'])\n",
    "us_counties = us_counties.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "stunning-charleston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'county', 'state', 'fips', 'cases', 'deaths'], dtype='object')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_counties.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "elementary-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_api = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND'\n",
    "token = 'rilsfDWJGSwodWyqrUaOsREORAwwngJa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "single-medicaid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 counties\n",
      "6059.0 connected\n",
      "6037.0 connected\n",
      "6085.0 connected\n",
      "6075.0 connected\n",
      "6073.0 connected\n",
      "6023.0 connected\n",
      "6067.0 connected\n",
      "6095.0 connected\n",
      "6041.0 connected\n",
      "6055.0 connected\n",
      "6097.0 connected\n",
      "6001.0 connected\n",
      "6061.0 connected\n",
      "6081.0 connected\n",
      "6013.0 connected\n",
      "6113.0 connected\n",
      "6019.0 connected\n",
      "6039.0 connected\n",
      "6065.0 connected\n",
      "6087.0 connected\n",
      "6089.0 connected\n",
      "6077.0 connected\n",
      "6111.0 connected\n",
      "6099.0 connected\n",
      "6107.0 connected\n",
      "6069.0 connected\n",
      "6079.0 connected\n",
      "6071.0 connected\n",
      "6083.0 connected\n",
      "6057.0 connected\n",
      "6029.0 connected\n",
      "6053.0 connected\n",
      "6045.0 connected\n",
      "6005.0 connected\n",
      "6025.0 connected\n",
      "6007.0 connected\n",
      "6017.0 connected\n",
      "6093.0 connected\n",
      "6115.0 connected\n",
      "6009.0 connected\n",
      "6047.0 connected\n",
      "6051.0 connected\n",
      "6027.0 connected\n",
      "6101.0 connected\n",
      "6011.0 connected\n",
      "6031.0 connected\n",
      "6021.0 connected\n",
      "6109.0 connected\n",
      "6003.0 connected\n",
      "6063.0 connected\n",
      "6015.0 connected\n",
      "6103.0 connected\n",
      "6033.0 connected\n",
      "6043.0 connected\n",
      "6105.0 connected\n",
      "6091.0 connected\n",
      "6035.0 connected\n",
      "6049.0 connected\n"
     ]
    }
   ],
   "source": [
    "county_weather = get_county_weather('California')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "thirty-summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['metadata', 'results'])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = noaa_api+'&locationid=FIPS:53061&startdate=2020-01-01&enddate=2020-01-03&datatypeid=TAVG&limit=1000'\n",
    "r = requests.get(l, headers={'token': token})\n",
    "#load the api response as a json\n",
    "print(r)\n",
    "d = json.loads(r.text)\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "sound-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resultset': {'offset': 1, 'count': 6, 'limit': 1000}}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "entire-lover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2020-01-03T00:00:00',\n",
       " 'datatype': 'TAVG',\n",
       " 'station': 'GHCND:USS0021B48S',\n",
       " 'attributes': ',,T,',\n",
       " 'value': 35}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['results'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "sudden-overhead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique([item['date'] for item in d['results']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ranking-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [item['date'] for item in d['results']]\n",
    "values = [item['value'] for item in d['results']]\n",
    "df = pd.DataFrame({'TAVG': values, 'date': dates})\n",
    "df['fips'] = [53061] * len(d['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "comparable-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df.groupby(['fips', 'date'])['TAVG'].mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "dried-sculpture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>fips</th>\n",
       "      <th>mean_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01T00:00:00</td>\n",
       "      <td>53061</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02T00:00:00</td>\n",
       "      <td>53061</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03T00:00:00</td>\n",
       "      <td>53061</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date   fips  mean_temp\n",
       "0  2020-01-01T00:00:00  53061       25.0\n",
       "1  2020-01-02T00:00:00  53061       -6.0\n",
       "2  2020-01-03T00:00:00  53061       41.5"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('TAVG', axis=1)\n",
    "df = df.drop_duplicates(ignore_index=True)\n",
    "df['mean_temp'] = m\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "urban-narrative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>fips</th>\n",
       "      <th>mean_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01T00:00:00</td>\n",
       "      <td>53061</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02T00:00:00</td>\n",
       "      <td>53061</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03T00:00:00</td>\n",
       "      <td>53061</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01T00:00:00</td>\n",
       "      <td>53061</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02T00:00:00</td>\n",
       "      <td>53061</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03T00:00:00</td>\n",
       "      <td>53061</td>\n",
       "      <td>41.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date   fips  mean_temp\n",
       "0  2020-01-01T00:00:00  53061       25.0\n",
       "1  2020-01-02T00:00:00  53061       -6.0\n",
       "2  2020-01-03T00:00:00  53061       41.5\n",
       "0  2020-01-01T00:00:00  53061       25.0\n",
       "1  2020-01-02T00:00:00  53061       -6.0\n",
       "2  2020-01-03T00:00:00  53061       41.5"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pd.DataFrame()\n",
    "pd.concat((total, df, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-donor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
